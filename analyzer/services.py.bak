import os
import json
from typing import Dict, Any
import PyPDF2
from io import BytesIO

# OpenRouter Configuration
OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY', '')
OPENROUTER_BASE_URL = os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1')
LLM_MODEL = os.getenv('LLM_MODEL', 'anthropic/claude-3.5-sonnet:beta')
OPENROUTER_APP_NAME = os.getenv('OPENROUTER_APP_NAME', 'Paper Analyzer')
OPENROUTER_REFERER = os.getenv('OPENROUTER_REFERER', 'http://localhost:8000')


def extract_text_from_pdf(pdf_file) -> str:
    """
    Extract text content from a PDF file.

    Args:
        pdf_file: Django UploadedFile object

    Returns:
        str: Extracted text from the PDF
    """
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text_content = []

        # Extract text from all pages
        for page_num in range(len(pdf_reader.pages)):
            page = pdf_reader.pages[page_num]
            text = page.extract_text()
            if text.strip():
                text_content.append(f"--- Page {page_num + 1} ---\n{text}")

        return '\n\n'.join(text_content)
    except Exception as e:
        raise Exception(f"Error extracting text from PDF: {str(e)}")


def create_analysis_prompt(paper_text: str) -> str:
    """
    Create a comprehensive prompt for LLM to analyze a research paper.
    Focused purely on paper analysis for understanding and research purposes.

    Args:
        paper_text: Full text content of the research paper

    Returns:
        str: Formatted prompt for the LLM
    """
    prompt = f"""You are an expert research analyst specializing in academic paper analysis. Your task is to thoroughly analyze the following research paper and provide a comprehensive breakdown for research understanding.

Please analyze the paper and extract the following information:

## PAPER CONTENT:
{paper_text[:25000]}


## ANALYSIS REQUIREMENTS:

Please provide a detailed analysis with the following sections. Be specific, thorough, and extract exact information from the paper.

### PAPER METADATA
First, extract:
- Paper title (exact)
- All authors (list them all)
- Publication venue (conference/journal name, e.g., "ICCV 2023", "CVPR 2022", "IEEE Transactions on Pattern Analysis and Machine Intelligence")
- Publication year
- Paper URL (arXiv URL, official PDF link, or DOI link if mentioned)

### 1. ABSTRACT
Summarize the abstract in 2-3 sentences. What is the core focus of this paper?

### 2. INTRODUCTION
Provide a comprehensive introduction including:
- What is the research domain/field?
- What is the background context for this work?
- What is the related work? Summarize key prior approaches and their limitations
- How does this paper relate to or build upon existing research?
- What is the research gap or problem this paper addresses?

### 3. MOTIVATION
What problem or gap in existing research motivated this work?
- What are the key issues or limitations in current approaches?
- Why is this research necessary or timely?
- What real-world problem does it address?

### 4. CONTRIBUTION
What are the main contributions of this paper?
- Novel algorithms, methods, or frameworks proposed
- New datasets or benchmarks introduced
- Theoretical contributions or proofs
- Practical improvements over existing methods
- Be specific and list each contribution clearly

### 5. METHODOLOGY
Explain the technical approach in detail:
- What is the main idea or framework proposed?
- Describe the key technical components or architecture
- What algorithms or techniques are used?
- How does the method work (step-by-step)?
- Include any mathematical formulations or key equations
- What makes this approach innovative or unique?

### 6. EXPERIMENTS & RESULTS
Describe the experimental evaluation:
- What datasets were used?
- What baselines or comparison methods were evaluated against?
- What metrics were used for evaluation?
- What are the key quantitative results?
- Summarize the main experimental findings
- Any significant performance improvements or discoveries?
- Include specific numbers/percentages when available

### 7. LIMITATIONS & CHALLENGES
Discuss the limitations acknowledged by the authors:
- What are the stated limitations of the proposed method?
- What assumptions does the method make?
- What scenarios or conditions might affect performance?
- Any computational or resource constraints?
- What challenges remain unsolved?

### 8. FUTURE WORK
What future work do the authors suggest?
- What extensions or improvements are proposed?
- What open questions remain?
- What directions for future research are identified?

### 9. CONCLUSION
Summarize the main conclusion:
- What are the key takeaways?
- How does this work advance the field?
- What is the broader impact?


## RESPONSE FORMAT:
Please provide your analysis in the following JSON format. **IMPORTANT: Use Markdown formatting within each JSON field:**

- Use bullet points with `-` for lists
- Use numbered lists with `1.` `2.` `3.` for sequential items
- Use `**bold**` for key terms and emphasis
- Use `###` for subsections within longer responses
- Use proper spacing and line breaks for readability

{{
    "title": "Exact paper title",
    "authors": "Author1, Author2, Author3",
    "venue": "Conference/Journal Name",
    "year": "Publication Year",
    "paper_url": "https://arxiv.org/abs/...",
    "abstract": "Brief summary of the abstract...",
    "introduction": "Background and related work. Use subsections: ### Background\\n### Related Work\\n### Research Gap...",
    "motivation": "- Key issue 1\\n- Key issue 2\\n- Problem addressed...",
    "contribution": "- Contribution 1\\n- Contribution 2\\n- Contribution 3...",
    "how_does_paper_do": "Technical methodology with subsections: ### Main Idea\\n### Framework\\n### Algorithm\\n### Implementation details...",
    "what_does_paper_do": "1. Dataset used\\n2. Evaluation metrics\\n3. Results: ...\\n4. Key findings...",
    "limitations_challenges": "- Limitation 1\\n- Limitation 2\\n- Assumption/Constraint...",
    "future_work": "1. Future direction 1\\n2. Future direction 2...",
    "conclusion": "Main conclusions, impact, and significance..."
}}

Ensure your analysis is:
- Accurate and based only on the paper content
- Specific and detailed, not vague
- Well-structured with Markdown formatting
- Use proper list formatting (bullet points or numbered lists)
- Professional and scholarly in tone
- Comprehensive enough for deep understanding of the research
"""

    return prompt


def create_ppt_generation_prompt(paper_text: str, student_name: str = "Your Name", student_id: str = "Student ID") -> str:
    """
    Create a specialized prompt for LLM to analyze a research paper for PPT generation.
    This prompt is optimized for generating presentation-ready content with specific
    focus on what should appear on slides, following the academic presentation template.

    Args:
        paper_text: Full text content of the research paper
        student_name: Name of the student presenting
        student_id: Student ID

    Returns:
        str: Formatted prompt for the LLM
    """
    prompt = f"""You are an expert academic presentation designer. Your task is to analyze the following research paper and extract content specifically for generating a professional PowerPoint presentation following the standard academic presentation template (approximately 12-16 slides).

## PAPER CONTENT:
{paper_text[:30000]}

## PRESENTATION TEMPLATE STRUCTURE:

This analysis will be used to generate an academic presentation with the following exact structure:

**Slide 1: Cover Slide**
- Paper title (large, bold)
- Authors and venue
- Student name and ID

**Slide 2: Introduction**
- Research background and context
- Related work summary
- Research gap identification

**Slide 3: Literature Review / Related Work**
- Key prior approaches (3-4 items)
- Limitations of existing methods
- How this paper differs

**Slide 4: Problem Statement / Motivation**
- Core problem definition
- Current challenges
- Why this research matters

**Slide 5: Main Idea & Contributions**
- Core innovation (1 sentence)
- Key contributions (3-5 bullet points)
- Framework overview

**Slide 6: Methodology Overview**
- High-level approach
- System/framework architecture

**Slide 7: Technical Details**
- Key algorithms or techniques
- Important equations or formulas
- Implementation details

**Slide 8: Experimental Setup**
- Datasets used
- Evaluation metrics
- Baseline methods
- Implementation details

**Slide 9: Results - Quantitative**
- Main quantitative results
- Performance metrics with specific numbers
- Comparisons with baselines

**Slide 10: Results - Qualitative Analysis**
- Key findings and insights
- Performance analysis
- Ablation studies (if available)

**Slide 11: Discussion**
- Interpretation of results
- Strengths and limitations
- Practical implications

**Slide 12: Conclusion**
- Summary of contributions
- Impact on the field
- Future work directions

**Slide 13: Thank You / Q&A**
- Contact information
- References placeholder

## CRITICAL CONTENT REQUIREMENTS:

**IMPORTANT: This is for a PRESENTATION to be delivered publicly. Content must be SHORT, CONCISE, and EASY TO READ from a distance.**

For EACH section below, provide CONCISE, PRESENTATION-READY content:
- **Keep bullet points SHORT**: Maximum 10-15 words per bullet (one line)
- **Use phrases, not paragraphs**: Each bullet should be a quick read (2-3 seconds)
- **Limit bullets per slide**: Maximum 6 bullet points per slide for readability
- **Use simple language**: Avoid jargon where possible, use clear terms
- **Focus on key points**: Only the most important information for each slide
- **Presentation format**: Think of what you would say verbally, write it concisely

BAD EXAMPLE (too long):
- "We propose a novel efficient attention mechanism that reduces computational complexity from O(n²) to O(n log n) while maintaining competitive accuracy on standard benchmarks."

GOOD EXAMPLE (short & readable):
- "Novel efficient attention: reduces O(n²) → O(n log n) complexity"
- "Maintains competitive accuracy on standard benchmarks"

### 1. PAPER METADATA
Extract exactly:
- Paper title (verbatim)
- All authors with affiliations if available
- Publication venue (e.g., "CVPR 2024", "NeurIPS 2023")
- Publication year
- Paper URL (arXiv, official link, or DOI)

### 2. INTRODUCTION (for Slide 2)
Provide CONCISE content:
- **Research Domain**: 2-3 SHORT bullets (5-8 words each) explaining the field and context
- **Related Work**: 3-4 SHORT bullets covering key prior papers and limitations
- **Research Gap**: 1-2 clear bullets identifying what's missing
- **Your Approach**: 1 SHORT sentence on how this paper addresses the gap

Example format (SHORT & READABLE):
```
- Deep learning for image recognition advanced significantly
- Vision Transformer (ViT) showed promising results
- Challenge: high computational cost for edge devices
- ViT (2020): pure transformer for vision tasks
- Swin (2021): hierarchical structure, efficient attention
- Gap: Need efficient transformers for edge deployment
- Our approach: novel efficient attention mechanism
```

### 3. LITERATURE REVIEW (for Slide 3)
Provide COMPREHENSIVE related work:
- List 5-7 key prior approaches with details:
  - Method name and authors
  - Key idea or contribution
  - Main limitation (1 sentence each)
- Organize chronologically or thematically
- Show progression of research in the field

### 4. PROBLEM STATEMENT / MOTIVATION (for Slide 4)
Provide compelling problem statement:
- **Core Problem**: 2-3 clear sentences defining what problem is being solved
- **Current Limitations**: 4-5 bullet points on specific issues with existing approaches
- **Why Important**: 2-3 bullets on real-world impact or significance
- **Key Challenges**: 2-3 bullets on technical hurdles

### 5. MAIN IDEA & CONTRIBUTIONS (for Slide 5)
Extract detailed contributions:
- **Main Idea**: One clear, comprehensive sentence (20-30 words) summarizing the core innovation
- **Key Contributions**: 4-6 detailed bullet points, each describing a specific contribution
- **Framework Overview**: 3-4 sentences explaining the high-level approach suitable for a diagram

Each contribution should be specific:
```
- Novel efficient attention mechanism: We propose a sparse attention pattern that reduces complexity from O(n²) to O(n log n)
- Multi-scale feature fusion: We introduce a new fusion module that combines features at different scales for better representation
- Self-distillation training: We design a self-supervised training approach that improves performance without external data
- Comprehensive evaluation: We validate on 5 benchmarks and achieve state-of-the-art results with 40% fewer parameters
```

### 6. METHODOLOGY OVERVIEW (for Slide 6)
Provide comprehensive technical overview:
- **System Overview**: 3-4 sentences explaining the overall framework/pipeline
- **Key Components**: List 4-6 main components with brief descriptions
- **Architecture Flow**: Describe how components connect and work together
- Format for creating a system diagram

### 7. TECHNICAL DETAILS (for Slide 7)
Extract in-depth technical content:
- **Key Algorithms**: 2-3 detailed algorithms or techniques with descriptions
- **Mathematical Formulations**: Include key equations, formulas, or mathematical insights (if available)
- **Implementation Details**: 3-4 bullets on specific implementation choices
- **Novel Technical Aspects**: What's technically innovative about the approach

### 8. EXPERIMENTAL SETUP (for Slide 8)
Provide detailed experimental configuration:
- **Datasets**: 3-4 bullet points per dataset (name, size, characteristics, why used)
- **Evaluation Metrics**: List all metrics with brief explanations (4-6 metrics)
- **Baseline Methods**: 5-7 methods compared against with brief descriptions
- **Implementation Settings**: Training details (optimizer, learning rate, batch size, epochs, hardware)
- **Data Splits**: Training/validation/test split information

Example:
```
- ImageNet-1K: Standard large-scale dataset with 1.28M training images and 50K validation images across 1000 categories
- COCO 2017: Object detection dataset with 118K training images and 5K validation images
- ADE20K: Scene parsing dataset with 20K images for semantic segmentation
- Metrics: Top-1 accuracy - standard classification accuracy measure
- Metrics: Top-5 accuracy - percentage of correct predictions in top 5
- Metrics: FLOPs - floating point operations for computational cost
- Metrics: Parameters - number of trainable parameters
- Metrics: Inference time - milliseconds per image on standard hardware
- Baselines: ViT-B/16 - Vision Transformer base model with 16x16 patch size
- Baselines: Swin-T - Swin Transformer tiny variant
- Baselines: ResNet-50 - Classic convolutional neural network baseline
- Training: AdamW optimizer, lr=3e-3, batch size=1024, 300 epochs
```

### 9. RESULTS - QUANTITATIVE (for Slide 9)
Extract specific quantitative results:
- **Main Results**: Provide 4-6 bullet points with specific numbers
  - Include method names, datasets, metrics, and exact values
  - Show comparisons with baselines
  - Highlight improvements with percentages
- **Performance Table**: Format results suitable for a table
- **Key Achievements**: What specific metrics improved and by how much

Example format:
```
- ImageNet-1K Top-1 Accuracy: Our Method 84.2%, ViT-B 81.8%, Swin-T 81.3% (+2.9% improvement)
- ImageNet-1K Top-5 Accuracy: Our Method 96.8%, ViT-B 95.7%, Swin-T 95.5% (+1.3% improvement)
- COCO mAP: Our Method 52.4%, DETR (baseline) 42.0%, (+10.4% improvement)
- Computational Efficiency: 40% fewer FLOPs compared to ViT-B (4.2G vs 7.1G)
- Inference Speed: 15ms per image vs 25ms for ViT-B (40% faster)
- Parameters: 21M parameters vs 86M for ViT-B (75% reduction)
```

### 10. RESULTS - QUALITATIVE ANALYSIS (for Slide 10)
Provide detailed results analysis:
- **Ablation Studies**: 3-4 bullet points on component effectiveness (if available)
- **Visualization Results**: Describe key qualitative findings (2-3 bullets)
- **Error Analysis**: What cases does the method fail on (2-3 bullets)
- **Comparison Analysis**: Why does this approach work better (2-3 bullets)
- **Cross-Dataset Results**: Performance on different datasets (if available)

### 11. DISCUSSION (for Slide 11)
Provide thoughtful analysis:
- **Result Interpretation**: 3-4 bullets explaining what results mean
- **Strengths**: 3-4 bullets on what makes this approach strong
- **Limitations**: 3-4 bullets on acknowledged limitations
- **Practical Implications**: 2-3 bullets on real-world applications
- **Broader Impact**: 2-3 bullets on significance to the field

### 12. CONCLUSION (for Slide 12)
Provide comprehensive conclusion:
- **Summary**: 3-4 bullet points summarizing main contributions
- **Impact**: 2-3 sentences on how this advances the field
- **Future Work**: 4-5 specific bullet points on potential extensions or improvements
- **Takeaway Message**: One clear sentence summarizing the key message

## RESPONSE FORMAT:
Provide your analysis in JSON format. BE COMPREHENSIVE and DETAILED - each section should have substantial content for complete slides.

{{
    "title": "Exact Paper Title",
    "authors": "Author1, Author2, Author3",
    "venue": "Conference/Journal Name",
    "year": "Publication Year",
    "paper_url": "https://...",

    "introduction": "### Research Domain\\n- Bullet point 1 with full explanation\\n- Bullet point 2 with full explanation\\n- Bullet point 3 with full explanation\\n\\n### Related Work\\n- Prior work 1: detailed description including author and key contribution\\n- Prior work 2: detailed description including limitation\\n- Prior work 3: detailed description\\n- Prior work 4: detailed description\\n\\n### Research Gap\\n- Gap 1: detailed explanation\\n- Gap 2: detailed explanation\\n\\n### Our Approach\\n- Brief overview of our solution",

    "literature_review": "1. Method Name (Authors, Year): Key idea and contribution\\n   Limitation: Specific limitation of this approach\\n\\n2. Method Name (Authors, Year): Key idea and contribution\\n   Limitation: Specific limitation of this approach\\n\\n3. Method Name (Authors, Year): Key idea and contribution\\n   Limitation: Specific limitation of this approach\\n\\n4. Method Name (Authors, Year): Key idea and contribution\\n   Limitation: Specific limitation of this approach\\n\\n5. Method Name (Authors, Year): Key idea and contribution\\n   Limitation: Specific limitation of this approach",

    "motivation": "### Core Problem\\nClear statement of the problem being solved (2-3 sentences)\\n\\n### Current Limitations\\n- Limitation 1: detailed explanation of existing problem\\n- Limitation 2: detailed explanation\\n- Limitation 3: detailed explanation\\n- Limitation 4: detailed explanation\\n\\n### Why Important\\n- Significance point 1\\n- Significance point 2\\n- Significance point 3\\n\\n### Key Challenges\\n- Challenge 1\\n- Challenge 2\\n- Challenge 3",

    "contribution": "### Main Idea\\nOne comprehensive sentence (20-30 words) summarizing the core innovation\\n\\n### Key Contributions\\n- Contribution 1: detailed description with specific technical details\\n- Contribution 2: detailed description with specific technical details\\n- Contribution 3: detailed description with specific technical details\\n- Contribution 4: detailed description with specific technical details\\n- Contribution 5: detailed description with specific technical details\\n\\n### Framework Overview\\n- Framework component 1: description\\n- Framework component 2: description\\n- Framework component 3: description\\n- Framework component 4: description",

    "how_does_paper_do": "### System Overview\\n3-4 sentences explaining the overall framework\\n\\n### Key Components\\n1. Component 1: detailed description of what it does and how it works\\n2. Component 2: detailed description of what it does and how it works\\n3. Component 3: detailed description of what it does and how it works\\n4. Component 4: detailed description of what it does and how it works\\n5. Component 5: detailed description of what it does and how it works\\n\\n### Architecture Flow\\n- Step 1: description\\n- Step 2: description\\n- Step 3: description\\n- Step 4: description\\n\\n### Technical Details\\n- Key algorithm or technique 1 with description\\n- Key algorithm or technique 2 with description\\n- Key algorithm or technique 3 with description",

    "what_does_paper_do": "### Datasets\\n- Dataset 1: detailed description including size, characteristics, and why used\\n- Dataset 2: detailed description including size, characteristics, and why used\\n- Dataset 3: detailed description including size, characteristics, and why used\\n\\n### Evaluation Metrics\\n- Metric 1: detailed explanation of what it measures\\n- Metric 2: detailed explanation of what it measures\\n- Metric 3: detailed explanation of what it measures\\n- Metric 4: detailed explanation of what it measures\\n- Metric 5: detailed explanation of what it measures\\n\\n### Baseline Methods\\n- Baseline 1: brief description of the method\\n- Baseline 2: brief description of the method\\n- Baseline 3: brief description of the method\\n- Baseline 4: brief description of the method\\n- Baseline 5: brief description of the method\\n\\n### Implementation Settings\\n- Training: optimizer details, learning rate, batch size, epochs\\n- Hardware: computational resources used\\n- Data split: training/validation/test distribution\\n\\n### Key Quantitative Results\\n- Dataset 1 - Metric 1: Our Method X.X%, Baseline 1 Y.Y%, Baseline 2 Z.Z% (improvement: +A.A%)\\n- Dataset 1 - Metric 2: Our Method X.X%, Baseline 1 Y.Y% (improvement: +B.B%)\\n- Dataset 2 - Metric 1: Our Method X.X%, Baseline Y.Y% (improvement: +C.C%)\\n- Dataset 2 - Metric 2: Our Method X.X%, Baseline Y.Y% (improvement: +D.D%)\\n- Computational: FLOPs, parameters, inference time with specific numbers\\n\\n### Main Findings\\n- Finding 1: detailed explanation of key result\\n- Finding 2: detailed explanation of key result\\n- Finding 3: detailed explanation of key result\\n- Finding 4: detailed explanation of key result",

    "results_analysis": "### Ablation Studies\\n- Ablation 1: what was tested and what was learned\\n- Ablation 2: what was tested and what was learned\\n- Ablation 3: what was tested and what was learned\\n\\n### Performance Analysis\\n- Analysis point 1: detailed explanation\\n- Analysis point 2: detailed explanation\\n- Analysis point 3: detailed explanation\\n\\n### Error Analysis\\n- Error type 1: when and why it occurs\\n- Error type 2: when and why it occurs\\n\\n### Comparison Insights\\n- Insight 1: why our approach outperforms\\n- Insight 2: what makes the difference",

    "discussion": "### Result Interpretation\\n- Interpretation point 1: what the results mean\\n- Interpretation point 2: what the results mean\\n- Interpretation point 3: what the results mean\\n\\n### Strengths\\n- Strength 1: detailed explanation\\n- Strength 2: detailed explanation\\n- Strength 3: detailed explanation\\n\\n### Limitations\\n- Limitation 1: detailed explanation\\n- Limitation 2: detailed explanation\\n- Limitation 3: detailed explanation\\n\\n### Practical Implications\\n- Implication 1: how this can be applied\\n- Implication 2: real-world applications\\n\\n### Broader Impact\\n- Impact point 1: significance to the field\\n- Impact point 2: future directions enabled",

    "conclusion": "### Summary of Contributions\\n- Contribution 1: summary of main achievement\\n- Contribution 2: summary of main achievement\\n- Contribution 3: summary of main achievement\\n- Contribution 4: summary of main achievement\\n\\n### Impact\\n2-3 sentences on how this work advances the field and opens new directions\\n\\n### Future Work\\n- Future direction 1: specific extension or improvement\\n- Future direction 2: specific extension or improvement\\n- Future direction 3: specific extension or improvement\\n- Future direction 4: specific extension or improvement\\n- Future direction 5: open problem or challenge\\n\\n### Key Takeaway\\nOne clear sentence that summarizes the main message of this work",

    "abstract": "Brief 2-3 sentence summary of the entire paper for speaker notes or overview",

    "future_work": "1. Specific extension 1: detailed description\\n2. Specific extension 2: detailed description\\n3. Open problem 1: detailed description\\n4. Open problem 2: detailed description\\n5. Open problem 3: detailed description"
}}

## ABSOLUTELY CRITICAL REQUIREMENTS:

1. **BE COMPREHENSIVE**: Each section must contain SUBSTANTIAL content. Do NOT be brief. Provide enough content for complete, informative slides.

2. **BE SPECIFIC**: Include exact numbers, percentages, metrics, model names, dataset names, author names, years, etc.

3. **BE STRUCTURED**: Use ### subsections to clearly indicate slide breaks. Each ### should represent content for one slide.

4. **USE BULLET POINTS**: Format content with - or numbered lists for easy conversion to slides.

5. **BE DETAILED**: Each bullet point should be a complete, meaningful statement, not a fragment.

6. **NO VAGUE STATEMENTS**: Avoid phrases like "better performance", "improved results". Instead say "achieved 84.2% accuracy vs 81.3% baseline (+2.9% improvement)".

7. **COMPLETE CONTENT**: Ensure all sections are filled. If a paper doesn't explicitly have a section, infer and create reasonable content based on the paper's context.

8. **ACADEMIC TONE**: Use professional, scholarly language appropriate for academic presentations.

9. **EXTRACTION ACCURACY**: Extract information ACCURATELY from the paper. Do not invent or hallucinate content. If information is not available, state so clearly.

Your output will be used to generate actual PowerPoint slides. Make it presentation-ready, comprehensive, and impressive.
"""

    return prompt


def call_llm_api(prompt: str) -> Dict[str, Any]:
    """
    Call the OpenRouter LLM API to analyze the paper.

    Args:
        prompt: The formatted prompt to send to the LLM

    Returns:
        dict: Parsed JSON response from the LLM

    Raises:
        Exception: If API call fails or returns invalid response
    """
    try:
        return _call_openrouter(prompt)
    except Exception as e:
        raise Exception(f"Error calling OpenRouter API: {str(e)}")


def _call_openrouter(prompt: str) -> Dict[str, Any]:
    """
    Call OpenRouter API for paper analysis.
    OpenRouter provides access to multiple LLMs through a unified API.
    """
    try:
        from openai import OpenAI

        # Your app name and URL for OpenRouter ranking
        # See https://openrouter.ai/docs/quick-start
        headers = {
            'HTTP-Referer': OPENROUTER_REFERER,
            'X-Title': OPENROUTER_APP_NAME,
        }

        client = OpenAI(
            base_url=OPENROUTER_BASE_URL,
            api_key=OPENROUTER_API_KEY,
            default_headers=headers
        )

        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert research analyst specializing in academic paper analysis. You always respond with valid JSON. Format all text content using Markdown with proper bullet points, numbered lists, and bold text for emphasis."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3,
            extra_body={
                'response_format': {"type": "json_object"}
            }
        )

        content = response.choices[0].message.content
        return json.loads(content)

    except Exception as e:
        # Some models on OpenRouter don't support response_format
        # Try again without it
        try:
            from openai import OpenAI

            headers = {
                'HTTP-Referer': OPENROUTER_REFERER,
                'X-Title': OPENROUTER_APP_NAME,
            }

            client = OpenAI(
                base_url=OPENROUTER_BASE_URL,
                api_key=OPENROUTER_API_KEY,
                default_headers=headers
            )

            response = client.chat.completions.create(
                model=LLM_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert research analyst specializing in academic paper analysis. IMPORTANT: You must respond ONLY with valid JSON, no additional text or explanation. Format all text content using Markdown with proper bullet points, numbered lists, and bold text for emphasis."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3
            )

            content = response.choices[0].message.content

            # Try to extract JSON from the response if it contains extra text
            import re
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                content = json_match.group(0)

            return json.loads(content)

        except Exception as e2:
            raise Exception(f"OpenRouter API error: {str(e2)}")


def analyze_paper(pdf_file) -> Dict[str, str]:
    """
    Main function to analyze a research paper PDF.
    Uses the standard analysis prompt for research understanding.

    Args:
        pdf_file: Django UploadedFile object

    Returns:
        dict: Analysis results with all sections
    """
    # Step 1: Extract text from PDF
    paper_text = extract_text_from_pdf(pdf_file)

    if not paper_text or len(paper_text.strip()) < 100:
        raise Exception("Unable to extract sufficient text from the PDF. Please ensure it's a valid text-based PDF.")

    # Step 2: Create analysis prompt
    prompt = create_analysis_prompt(paper_text)

    # Step 3: Call LLM API
    analysis_result = call_llm_api(prompt)

    return analysis_result


def analyze_paper_for_ppt(pdf_file, student_name: str = "Your Name", student_id: str = "Student ID") -> Dict[str, str]:
    """
    Analyze a research paper PDF specifically for PPT generation.
    Uses the PPT-optimized prompt that focuses on presentation-ready content.

    Args:
        pdf_file: Django UploadedFile object
        student_name: Name of the student presenting
        student_id: Student ID

    Returns:
        dict: Analysis results optimized for presentation generation
    """
    # Step 1: Extract text from PDF
    paper_text = extract_text_from_pdf(pdf_file)

    if not paper_text or len(paper_text.strip()) < 100:
        raise Exception("Unable to extract sufficient text from the PDF. Please ensure it's a valid text-based PDF.")

    # Step 2: Create PPT-specific analysis prompt
    prompt = create_ppt_generation_prompt(paper_text, student_name, student_id)

    # Step 3: Call LLM API
    analysis_result = call_llm_api(prompt)

    return analysis_result
